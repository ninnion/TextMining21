{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/yonas/Desktop/GitHub/Text-Mining/TextMining21/Reddit_Julian_TOTAL-klassifiziert.csv\")\n",
    "df2 = pd.read_csv(\"/Users/yonas/Desktop/GitHub/Text-Mining/TextMining21/Reddit_Marek_klassifiziert.csv\")\n",
    "df3 = pd.read_csv(\"/Users/yonas/Desktop/GitHub/Text-Mining/TextMining21/Reddit_Yonas_Total_Klassifiziert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets = pd.concat([df1, df2, df3], axis=0, join='inner')\n",
    "Atweets = Atweets.sort_values(by='index')\n",
    "Atweets = Atweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punktuierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(txt):\n",
    "    txt_nopunt = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    return txt_nopunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission\"] = Atweets[\"submission\"].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    tokens = re.split(\"\\W+\", txt)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submissions_tokenized\"] = Atweets[\"submission\"].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopw√∂rter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.append(\"ll\")\n",
    "stopwords.append(\"im\")\n",
    "stopwords.append(\"youre\")\n",
    "stopwords.append(\"youve\")\n",
    "stopwords.append(\"youll\")\n",
    "stopwords.append(\"youd\")\n",
    "stopwords.append(\"shes\")\n",
    "stopwords.append(\"its\")\n",
    "stopwords.append(\"thatll\")\n",
    "stopwords.append(\"dont\")\n",
    "stopwords.append(\"shouldve\")\n",
    "stopwords.append(\"arent\")\n",
    "stopwords.append(\"couldnt\")\n",
    "stopwords.append(\"didnt\")\n",
    "stopwords.append(\"doesnt\")\n",
    "stopwords.append(\"hadnt\")\n",
    "stopwords.append(\"havent\")\n",
    "stopwords.append(\"isnt\")\n",
    "stopwords.append(\"mightnt\")\n",
    "stopwords.append(\"neednt\")\n",
    "stopwords.append(\"shant\")\n",
    "stopwords.append(\"shouldnt\")\n",
    "stopwords.append(\"wasnt\")\n",
    "stopwords.append(\"werent\")\n",
    "stopwords.append(\"wont\")\n",
    "stopwords.append(\"wouldnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(txt_tokenized):\n",
    "    txt_clean = [word for word in txt_tokenized if word not in stopwords]\n",
    "    return txt_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_no_stopwords\"] = Atweets[\"submissions_tokenized\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-Bereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_nostop\"] = Atweets[\"submission\"].apply(lambda x: clean_text(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_stemmed\"] = Atweets[\"submission_nostop\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(token_txt):\n",
    "    text = [wn.lemmatize(word) for word in token_txt]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_lemmatized\"] = Atweets[\"submission_nostop\"].apply(lambda x: lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>submission</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>submissions_tokenized</th>\n",
       "      <th>submission_no_stopwords</th>\n",
       "      <th>submission_nostop</th>\n",
       "      <th>submission_stemmed</th>\n",
       "      <th>submission_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I see that many countries are working hard to ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[i, see, that, many, countries, are, working, ...</td>\n",
       "      <td>[see, many, countries, working, hard, publish,...</td>\n",
       "      <td>[see, many, countries, working, hard, publish,...</td>\n",
       "      <td>[see, mani, countri, work, hard, publish, news...</td>\n",
       "      <td>[see, many, country, working, hard, publish, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>httpwwwtheguardiancomtechnology2013oct29bitcoi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Because I see a lot of down and out people who...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[because, i, see, a, lot, of, down, and, out, ...</td>\n",
       "      <td>[see, lot, people, fucked, loanswhat, think, r...</td>\n",
       "      <td>[see, lot, people, fucked, loanswhat, think, r...</td>\n",
       "      <td>[see, lot, peopl, fuck, loanswhat, think, rain...</td>\n",
       "      <td>[see, lot, people, fucked, loanswhat, think, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>so like many im not 100 clear on how LN functi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[so, like, many, im, not, 100, clear, on, how,...</td>\n",
       "      <td>[like, many, 100, clear, ln, functions, granul...</td>\n",
       "      <td>[like, many, 100, clear, ln, functions, granul...</td>\n",
       "      <td>[like, mani, 100, clear, ln, function, granula...</td>\n",
       "      <td>[like, many, 100, clear, ln, function, granula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Think i missed the Bottom  what about you\\n\\ne...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[think, i, missed, the, bottom, what, about, y...</td>\n",
       "      <td>[think, missed, bottom, edit, damn, autocorrec...</td>\n",
       "      <td>[think, missed, bottom, edit, damn, autocorrec...</td>\n",
       "      <td>[think, miss, bottom, edit, damn, autocorrect,...</td>\n",
       "      <td>[think, missed, bottom, edit, damn, autocorrec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2594</td>\n",
       "      <td>I know there are a lot of walk throughs about ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[i, know, there, are, a, lot, of, walk, throug...</td>\n",
       "      <td>[know, lot, walk, throughs, getting, private, ...</td>\n",
       "      <td>[know, lot, walk, throughs, getting, private, ...</td>\n",
       "      <td>[know, lot, walk, through, get, privat, key, s...</td>\n",
       "      <td>[know, lot, walk, throughs, getting, private, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2595</td>\n",
       "      <td>how is a cryptocurrency exchange different tha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[how, is, a, cryptocurrency, exchange, differe...</td>\n",
       "      <td>[cryptocurrency, exchange, different, bank, le...</td>\n",
       "      <td>[cryptocurrency, exchange, different, bank, le...</td>\n",
       "      <td>[cryptocurr, exchang, differ, bank, less, prof...</td>\n",
       "      <td>[cryptocurrency, exchange, different, bank, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>2596</td>\n",
       "      <td>A US federal judge rejected Alibaba Group Hold...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[a, us, federal, judge, rejected, alibaba, gro...</td>\n",
       "      <td>[us, federal, judge, rejected, alibaba, group,...</td>\n",
       "      <td>[us, federal, judge, rejected, alibaba, group,...</td>\n",
       "      <td>[us, feder, judg, reject, alibaba, group, hold...</td>\n",
       "      <td>[u, federal, judge, rejected, alibaba, group, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>2597</td>\n",
       "      <td>Anyone know of any Also do most online shops a...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[anyone, know, of, any, also, do, most, online...</td>\n",
       "      <td>[anyone, know, also, online, shops, accept, lo...</td>\n",
       "      <td>[anyone, know, also, online, shops, accept, lo...</td>\n",
       "      <td>[anyon, know, also, onlin, shop, accept, lot, ...</td>\n",
       "      <td>[anyone, know, also, online, shop, accept, lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>2598</td>\n",
       "      <td>German children play with stacks of money dur...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[, german, children, play, with, stacks, of, m...</td>\n",
       "      <td>[, german, children, play, stacks, money, hype...</td>\n",
       "      <td>[, german, children, play, stacks, money, hype...</td>\n",
       "      <td>[, german, children, play, stack, money, hyper...</td>\n",
       "      <td>[, german, child, play, stack, money, hyperinf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         submission  sentiment  \\\n",
       "0         0  I see that many countries are working hard to ...        2.0   \n",
       "1         0  httpwwwtheguardiancomtechnology2013oct29bitcoi...        3.0   \n",
       "2         1  Because I see a lot of down and out people who...        2.0   \n",
       "3         1  so like many im not 100 clear on how LN functi...        3.0   \n",
       "4         2  Think i missed the Bottom  what about you\\n\\ne...        3.0   \n",
       "...     ...                                                ...        ...   \n",
       "2998   2594  I know there are a lot of walk throughs about ...        3.0   \n",
       "2999   2595  how is a cryptocurrency exchange different tha...        3.0   \n",
       "3000   2596  A US federal judge rejected Alibaba Group Hold...        3.0   \n",
       "3001   2597  Anyone know of any Also do most online shops a...        3.0   \n",
       "3002   2598   German children play with stacks of money dur...        3.0   \n",
       "\n",
       "                                  submissions_tokenized  \\\n",
       "0     [i, see, that, many, countries, are, working, ...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [because, i, see, a, lot, of, down, and, out, ...   \n",
       "3     [so, like, many, im, not, 100, clear, on, how,...   \n",
       "4     [think, i, missed, the, bottom, what, about, y...   \n",
       "...                                                 ...   \n",
       "2998  [i, know, there, are, a, lot, of, walk, throug...   \n",
       "2999  [how, is, a, cryptocurrency, exchange, differe...   \n",
       "3000  [a, us, federal, judge, rejected, alibaba, gro...   \n",
       "3001  [anyone, know, of, any, also, do, most, online...   \n",
       "3002  [, german, children, play, with, stacks, of, m...   \n",
       "\n",
       "                                submission_no_stopwords  \\\n",
       "0     [see, many, countries, working, hard, publish,...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [see, lot, people, fucked, loanswhat, think, r...   \n",
       "3     [like, many, 100, clear, ln, functions, granul...   \n",
       "4     [think, missed, bottom, edit, damn, autocorrec...   \n",
       "...                                                 ...   \n",
       "2998  [know, lot, walk, throughs, getting, private, ...   \n",
       "2999  [cryptocurrency, exchange, different, bank, le...   \n",
       "3000  [us, federal, judge, rejected, alibaba, group,...   \n",
       "3001  [anyone, know, also, online, shops, accept, lo...   \n",
       "3002  [, german, children, play, stacks, money, hype...   \n",
       "\n",
       "                                      submission_nostop  \\\n",
       "0     [see, many, countries, working, hard, publish,...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [see, lot, people, fucked, loanswhat, think, r...   \n",
       "3     [like, many, 100, clear, ln, functions, granul...   \n",
       "4     [think, missed, bottom, edit, damn, autocorrec...   \n",
       "...                                                 ...   \n",
       "2998  [know, lot, walk, throughs, getting, private, ...   \n",
       "2999  [cryptocurrency, exchange, different, bank, le...   \n",
       "3000  [us, federal, judge, rejected, alibaba, group,...   \n",
       "3001  [anyone, know, also, online, shops, accept, lo...   \n",
       "3002  [, german, children, play, stacks, money, hype...   \n",
       "\n",
       "                                     submission_stemmed  \\\n",
       "0     [see, mani, countri, work, hard, publish, news...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [see, lot, peopl, fuck, loanswhat, think, rain...   \n",
       "3     [like, mani, 100, clear, ln, function, granula...   \n",
       "4     [think, miss, bottom, edit, damn, autocorrect,...   \n",
       "...                                                 ...   \n",
       "2998  [know, lot, walk, through, get, privat, key, s...   \n",
       "2999  [cryptocurr, exchang, differ, bank, less, prof...   \n",
       "3000  [us, feder, judg, reject, alibaba, group, hold...   \n",
       "3001  [anyon, know, also, onlin, shop, accept, lot, ...   \n",
       "3002  [, german, children, play, stack, money, hyper...   \n",
       "\n",
       "                                  submission_lemmatized  \n",
       "0     [see, many, country, working, hard, publish, n...  \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...  \n",
       "2     [see, lot, people, fucked, loanswhat, think, r...  \n",
       "3     [like, many, 100, clear, ln, function, granula...  \n",
       "4     [think, missed, bottom, edit, damn, autocorrec...  \n",
       "...                                                 ...  \n",
       "2998  [know, lot, walk, throughs, getting, private, ...  \n",
       "2999  [cryptocurrency, exchange, different, bank, le...  \n",
       "3000  [u, federal, judge, rejected, alibaba, group, ...  \n",
       "3001  [anyone, know, also, online, shop, accept, lot...  \n",
       "3002  [, german, child, play, stack, money, hyperinf...  \n",
       "\n",
       "[3003 rows x 8 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Atweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [see, many, country, working, hard, publish, n...\n",
       "1       [httpwwwtheguardiancomtechnology2013oct29bitco...\n",
       "2       [see, lot, people, fucked, loanswhat, think, r...\n",
       "3       [like, many, 100, clear, ln, function, granula...\n",
       "4       [think, missed, bottom, edit, damn, autocorrec...\n",
       "                              ...                        \n",
       "2998    [know, lot, walk, throughs, getting, private, ...\n",
       "2999    [cryptocurrency, exchange, different, bank, le...\n",
       "3000    [u, federal, judge, rejected, alibaba, group, ...\n",
       "3001    [anyone, know, also, online, shop, accept, lot...\n",
       "3002    [, german, child, play, stack, money, hyperinf...\n",
       "Name: submission_lemmatized, Length: 3003, dtype: object"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Atweets[\"submission_lemmatized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_SENTIMENT = set([\"good\", \"according\", \"people\", \"fucked\"])\n",
    "\n",
    "NEGATIVE_SENTIMENT = set([\"bad\", \"among\", \"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    x = set(lemmatization(text))\n",
    "    \n",
    "    positive_count, negative_count = 0, 0\n",
    "\n",
    "    for word in x:\n",
    "        if word in POSITIVE_SENTIMENT:\n",
    "            positive_count += 1\n",
    "        elif word in NEGATIVE_SENTIMENT:\n",
    "            negative_count += 1\n",
    "\n",
    "    if positive_count > negative_count:\n",
    "        return 'POSITIVE'\n",
    "    else:\n",
    "        return 'NEGATIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(Atweets[\"submission_lemmatized\"].iloc[1] + Atweets[\"submission_lemmatized\"].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['see',\n",
       " 'lot',\n",
       " 'people',\n",
       " 'fucked',\n",
       " 'loanswhat',\n",
       " 'think',\n",
       " 'rain',\n",
       " 'changetip',\n",
       " 'bot',\n",
       " 'fucker',\n",
       " '']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Atweets[\"submission_lemmatized\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
