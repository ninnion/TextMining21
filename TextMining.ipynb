{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/julianalexander/Library/Mobile Documents/com~apple~CloudDocs/HSG/1. Semester MBI FS2021/8,049,1.00 Text Mining mit Python/TextMining21/Reddit_Julian_TOTAL-klassifiziert.csv\")\n",
    "df2 = pd.read_csv(\"/Users/julianalexander/Library/Mobile Documents/com~apple~CloudDocs/HSG/1. Semester MBI FS2021/8,049,1.00 Text Mining mit Python/TextMining21/Reddit_Marek_klassifiziert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets = pd.concat([df1, df2], axis=0, join='inner')\n",
    "Atweets = Atweets.sort_values(by='index')\n",
    "Atweets = Atweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punktuierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(txt):\n",
    "    txt_nopunt = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    return txt_nopunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission\"] = Atweets[\"submission\"].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    tokens = re.split(\"\\W+\", txt)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submissions_tokenized\"] = Atweets[\"submission\"].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(txt_tokenized):\n",
    "    txt_clean = [word for word in txt_tokenized if word not in stopwords]\n",
    "    return txt_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_no_stopwords\"] = Atweets[\"submissions_tokenized\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-Bereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_nostop\"] = Atweets[\"submission\"].apply(lambda x: clean_text(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_stemmed\"] = Atweets[\"submission_nostop\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(token_txt):\n",
    "    text = [wn.lemmatize(word) for word in token_txt]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atweets[\"submission_lemmatized\"] = Atweets[\"submission_nostop\"].apply(lambda x: lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>submission</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>submissions_tokenized</th>\n",
       "      <th>submission_no_stopwords</th>\n",
       "      <th>submission_nostop</th>\n",
       "      <th>submission_stemmed</th>\n",
       "      <th>submission_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I see that many countries are working hard to ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[i, see, that, many, countries, are, working, ...</td>\n",
       "      <td>[see, many, countries, working, hard, publish,...</td>\n",
       "      <td>[see, many, countries, working, hard, publish,...</td>\n",
       "      <td>[see, mani, countri, work, hard, publish, news...</td>\n",
       "      <td>[see, many, country, working, hard, publish, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>httpwwwtheguardiancomtechnology2013oct29bitcoi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "      <td>[httpwwwtheguardiancomtechnology2013oct29bitco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>so like many im not 100 clear on how LN functi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[so, like, many, im, not, 100, clear, on, how,...</td>\n",
       "      <td>[like, many, im, 100, clear, ln, functions, gr...</td>\n",
       "      <td>[like, many, im, 100, clear, ln, functions, gr...</td>\n",
       "      <td>[like, mani, im, 100, clear, ln, function, gra...</td>\n",
       "      <td>[like, many, im, 100, clear, ln, function, gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Because I see a lot of down and out people who...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[because, i, see, a, lot, of, down, and, out, ...</td>\n",
       "      <td>[see, lot, people, fucked, loanswhat, think, r...</td>\n",
       "      <td>[see, lot, people, fucked, loanswhat, think, r...</td>\n",
       "      <td>[see, lot, peopl, fuck, loanswhat, think, rain...</td>\n",
       "      <td>[see, lot, people, fucked, loanswhat, think, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>I started the sync a few days ago and it was f...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[i, started, the, sync, a, few, days, ago, and...</td>\n",
       "      <td>[started, sync, days, ago, fine, first, going,...</td>\n",
       "      <td>[started, sync, days, ago, fine, first, going,...</td>\n",
       "      <td>[start, sync, day, ago, fine, first, go, 46, e...</td>\n",
       "      <td>[started, sync, day, ago, fine, first, going, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2594</td>\n",
       "      <td>I know there are a lot of walk throughs about ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[i, know, there, are, a, lot, of, walk, throug...</td>\n",
       "      <td>[know, lot, walk, throughs, getting, private, ...</td>\n",
       "      <td>[know, lot, walk, throughs, getting, private, ...</td>\n",
       "      <td>[know, lot, walk, through, get, privat, key, s...</td>\n",
       "      <td>[know, lot, walk, throughs, getting, private, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2595</td>\n",
       "      <td>how is a cryptocurrency exchange different tha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[how, is, a, cryptocurrency, exchange, differe...</td>\n",
       "      <td>[cryptocurrency, exchange, different, bank, le...</td>\n",
       "      <td>[cryptocurrency, exchange, different, bank, le...</td>\n",
       "      <td>[cryptocurr, exchang, differ, bank, less, prof...</td>\n",
       "      <td>[cryptocurrency, exchange, different, bank, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2596</td>\n",
       "      <td>A US federal judge rejected Alibaba Group Hold...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[a, us, federal, judge, rejected, alibaba, gro...</td>\n",
       "      <td>[us, federal, judge, rejected, alibaba, group,...</td>\n",
       "      <td>[us, federal, judge, rejected, alibaba, group,...</td>\n",
       "      <td>[us, feder, judg, reject, alibaba, group, hold...</td>\n",
       "      <td>[u, federal, judge, rejected, alibaba, group, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2597</td>\n",
       "      <td>Anyone know of any Also do most online shops a...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[anyone, know, of, any, also, do, most, online...</td>\n",
       "      <td>[anyone, know, also, online, shops, accept, lo...</td>\n",
       "      <td>[anyone, know, also, online, shops, accept, lo...</td>\n",
       "      <td>[anyon, know, also, onlin, shop, accept, lot, ...</td>\n",
       "      <td>[anyone, know, also, online, shop, accept, lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2598</td>\n",
       "      <td>German children play with stacks of money dur...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[, german, children, play, with, stacks, of, m...</td>\n",
       "      <td>[, german, children, play, stacks, money, hype...</td>\n",
       "      <td>[, german, children, play, stacks, money, hype...</td>\n",
       "      <td>[, german, children, play, stack, money, hyper...</td>\n",
       "      <td>[, german, child, play, stack, money, hyperinf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2003 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         submission  sentiment  \\\n",
       "0         0  I see that many countries are working hard to ...        2.0   \n",
       "1         0  httpwwwtheguardiancomtechnology2013oct29bitcoi...        3.0   \n",
       "2         1  so like many im not 100 clear on how LN functi...        3.0   \n",
       "3         1  Because I see a lot of down and out people who...        2.0   \n",
       "4         2  I started the sync a few days ago and it was f...        2.0   \n",
       "...     ...                                                ...        ...   \n",
       "1998   2594  I know there are a lot of walk throughs about ...        3.0   \n",
       "1999   2595  how is a cryptocurrency exchange different tha...        3.0   \n",
       "2000   2596  A US federal judge rejected Alibaba Group Hold...        3.0   \n",
       "2001   2597  Anyone know of any Also do most online shops a...        3.0   \n",
       "2002   2598   German children play with stacks of money dur...        3.0   \n",
       "\n",
       "                                  submissions_tokenized  \\\n",
       "0     [i, see, that, many, countries, are, working, ...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [so, like, many, im, not, 100, clear, on, how,...   \n",
       "3     [because, i, see, a, lot, of, down, and, out, ...   \n",
       "4     [i, started, the, sync, a, few, days, ago, and...   \n",
       "...                                                 ...   \n",
       "1998  [i, know, there, are, a, lot, of, walk, throug...   \n",
       "1999  [how, is, a, cryptocurrency, exchange, differe...   \n",
       "2000  [a, us, federal, judge, rejected, alibaba, gro...   \n",
       "2001  [anyone, know, of, any, also, do, most, online...   \n",
       "2002  [, german, children, play, with, stacks, of, m...   \n",
       "\n",
       "                                submission_no_stopwords  \\\n",
       "0     [see, many, countries, working, hard, publish,...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [like, many, im, 100, clear, ln, functions, gr...   \n",
       "3     [see, lot, people, fucked, loanswhat, think, r...   \n",
       "4     [started, sync, days, ago, fine, first, going,...   \n",
       "...                                                 ...   \n",
       "1998  [know, lot, walk, throughs, getting, private, ...   \n",
       "1999  [cryptocurrency, exchange, different, bank, le...   \n",
       "2000  [us, federal, judge, rejected, alibaba, group,...   \n",
       "2001  [anyone, know, also, online, shops, accept, lo...   \n",
       "2002  [, german, children, play, stacks, money, hype...   \n",
       "\n",
       "                                      submission_nostop  \\\n",
       "0     [see, many, countries, working, hard, publish,...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [like, many, im, 100, clear, ln, functions, gr...   \n",
       "3     [see, lot, people, fucked, loanswhat, think, r...   \n",
       "4     [started, sync, days, ago, fine, first, going,...   \n",
       "...                                                 ...   \n",
       "1998  [know, lot, walk, throughs, getting, private, ...   \n",
       "1999  [cryptocurrency, exchange, different, bank, le...   \n",
       "2000  [us, federal, judge, rejected, alibaba, group,...   \n",
       "2001  [anyone, know, also, online, shops, accept, lo...   \n",
       "2002  [, german, children, play, stacks, money, hype...   \n",
       "\n",
       "                                     submission_stemmed  \\\n",
       "0     [see, mani, countri, work, hard, publish, news...   \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...   \n",
       "2     [like, mani, im, 100, clear, ln, function, gra...   \n",
       "3     [see, lot, peopl, fuck, loanswhat, think, rain...   \n",
       "4     [start, sync, day, ago, fine, first, go, 46, e...   \n",
       "...                                                 ...   \n",
       "1998  [know, lot, walk, through, get, privat, key, s...   \n",
       "1999  [cryptocurr, exchang, differ, bank, less, prof...   \n",
       "2000  [us, feder, judg, reject, alibaba, group, hold...   \n",
       "2001  [anyon, know, also, onlin, shop, accept, lot, ...   \n",
       "2002  [, german, children, play, stack, money, hyper...   \n",
       "\n",
       "                                  submission_lemmatized  \n",
       "0     [see, many, country, working, hard, publish, n...  \n",
       "1     [httpwwwtheguardiancomtechnology2013oct29bitco...  \n",
       "2     [like, many, im, 100, clear, ln, function, gra...  \n",
       "3     [see, lot, people, fucked, loanswhat, think, r...  \n",
       "4     [started, sync, day, ago, fine, first, going, ...  \n",
       "...                                                 ...  \n",
       "1998  [know, lot, walk, throughs, getting, private, ...  \n",
       "1999  [cryptocurrency, exchange, different, bank, le...  \n",
       "2000  [u, federal, judge, rejected, alibaba, group, ...  \n",
       "2001  [anyone, know, also, online, shop, accept, lot...  \n",
       "2002  [, german, child, play, stack, money, hyperinf...  \n",
       "\n",
       "[2003 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Atweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
